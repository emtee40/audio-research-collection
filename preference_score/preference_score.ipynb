{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "sys.path.insert(1, os.path.realpath(os.path.join(sys.path[0], os.pardir, os.pardir)))\n",
    "from frequency_response import FrequencyResponse\n",
    "from constants import ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.0, 21.0, 22.0, 24.0, 25.0, 27.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 43.0, 45.0, 48.0, 50.0, 53.0, 56.0, 60.0, 63.0, 67.0, 71.0, 75.0, 80.0, 85.0, 90.0, 95.0, 100.0, 106.0, 112.0, 118.0, 125.0, 132.0, 140.0, 150.0, 160.0, 170.0, 180.0, 190.0, 200.0, 212.0, 224.0, 236.0, 250.0, 265.0, 280.0, 300.0, 315.0, 335.0, 355.0, 375.0, 400.0, 425.0, 450.0, 475.0, 500.0, 530.0, 560.0, 600.0, 630.0, 670.0, 710.0, 750.0, 800.0, 850.0, 900.0, 950.0, 1000.0, 1060.0, 1120.0, 1180.0, 1250.0, 1320.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0, 2120.0, 2240.0, 2360.0, 2500.0, 2650.0, 2800.0, 3000.0, 3150.0, 3350.0, 3550.0, 3750.0, 4000.0, 4250.0, 4500.0, 4750.0, 5000.0, 5300.0, 5600.0, 6000.0, 6300.0, 6700.0, 7100.0, 7500.0, 8000.0, 8500.0, 9000.0, 9500.0, 10000.0, 10600.0, 11200.0, 11800.0, 12500.0, 13200.0, 14000.0, 15000.0, 16000.0, 17000.0, 18000.0, 19000.0, 20000.0]\n"
     ]
    }
   ],
   "source": [
    "with open('frequencies.csv', 'r', encoding='utf-8') as fh:\n",
    "    onear_frequencies = [float(x) for x in fh.read().strip().split('\\n')[::-1]]\n",
    "print(onear_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.0, 21.2, 22.4, 23.6, 25.0, 26.5, 28.0, 30.0, 31.5, 33.5, 35.5, 37.5, 40.0, 42.5, 45.0, 47.5, 50.0, 53.0, 56.0, 60.0, 63.0, 67.0, 71.0, 75.0, 80.0, 85.0, 90.0, 95.0, 100.0, 106.0, 112.0, 118.0, 125.0, 132.0, 140.0, 150.0, 160.0, 170.0, 180.0, 190.0, 200.0, 212.0, 224.0, 236.0, 250.0, 265.0, 280.0, 300.0, 315.0, 335.0, 355.0, 375.0, 400.0, 425.0, 450.0, 475.0, 500.0, 530.0, 560.0, 600.0, 630.0, 670.0, 710.0, 750.0, 800.0, 850.0, 900.0, 950.0, 1000.0, 1060.0, 1120.0, 1180.0, 1250.0, 1320.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0, 2120.0, 2240.0, 2360.0, 2500.0, 2650.0, 2800.0, 3000.0, 3150.0, 3350.0, 3550.0, 3750.0, 4000.0, 4250.0, 4500.0, 4750.0, 5000.0, 5300.0, 5600.0, 6000.0, 6300.0, 6700.0, 7100.0, 7500.0, 8000.0, 8500.0, 9000.0, 9500.0, 10000.0, 10600.0, 11200.0, 11800.0, 12500.0, 13200.0, 14000.0, 15000.0, 16000.0, 17000.0, 18000.0, 19000.0, 20000.0]\n"
     ]
    }
   ],
   "source": [
    "with open('inear_frequencies.csv', 'r', encoding='utf-8') as fh:\n",
    "    inear_frequencies = [float(x) for x in fh.read().strip().split('\\n')[::-1]]\n",
    "print(inear_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inear_frequencies = [20.0, 21.2, 22.4, 23.6, 25.0, 26.5, 28.0, 30.0, 31.5, 33.5, 35.5, 37.5, 40.0, 42.5, 45.0, 47.5, 50.0, 53.0, 56.0, 60.0, 63.0, 67.0, 71.0, 75.0, 80.0, 85.0, 90.0, 95.0, 100.0, 106.0, 112.0, 118.0, 125.0, 132.0, 140.0, 150.0, 160.0, 170.0, 180.0, 190.0, 200.0, 212.0, 224.0, 236.0, 250.0, 265.0, 280.0, 300.0, 315.0, 335.0, 355.0, 375.0, 400.0, 425.0, 450.0, 475.0, 500.0, 530.0, 560.0, 600.0, 630.0, 670.0, 710.0, 750.0, 800.0, 850.0, 900.0, 950.0, 1000.0, 1060.0, 1120.0, 1180.0, 1250.0, 1320.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0, 2120.0, 2240.0, 2360.0, 2500.0, 2650.0, 2800.0, 3000.0, 3150.0, 3350.0, 3550.0, 3750.0, 4000.0, 4250.0, 4500.0, 4750.0, 5000.0, 5300.0, 5600.0, 6000.0, 6300.0, 6700.0, 7100.0, 7500.0, 8000.0, 8500.0, 9000.0, 9500.0, 10000.0, 10600.0, 11200.0, 11800.0, 12500.0, 13200.0, 14000.0, 15000.0, 16000.0, 17000.0, 18000.0, 19000.0, 20000.0]\n",
    "inear_frequencies = np.array(inear_frequencies)\n",
    "def inear_score(fr):\n",
    "    fr = fr.copy()\n",
    "    fr.interpolate(inear_frequencies)\n",
    "    sl = np.logical_and(fr.frequency >= 20, fr.frequency <= 10000)\n",
    "    x = fr.frequency[sl]\n",
    "    xm = np.mean(x)\n",
    "    y = fr.error[sl]\n",
    "    ym = np.mean(y)\n",
    "\n",
    "    slope, _, _, _, _ = scipy.stats.linregress(np.log(x), y)\n",
    "    mean = np.mean(np.abs(fr.error[np.logical_and(fr.frequency >= 40, fr.frequency <= 10000)]))\n",
    "    std = np.std(y)\n",
    "    score = 100.0795 - 8.5 * std - 6.796 * np.abs(slope) - 3.475 * mean\n",
    "    # TODO: score and std differs from oratory1990 PDFs, could be Harman in-ear 2017-1 target\n",
    "        \n",
    "    return score, slope, mean, std, fr.error\n",
    "\n",
    "onear_frequencies = [20.0, 21.0, 22.0, 24.0, 25.0, 27.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 43.0, 45.0, 48.0, 50.0, 53.0, 56.0, 60.0, 63.0, 67.0, 71.0, 75.0, 80.0, 85.0, 90.0, 95.0, 100.0, 106.0, 112.0, 118.0, 125.0, 132.0, 140.0, 150.0, 160.0, 170.0, 180.0, 190.0, 200.0, 212.0, 224.0, 236.0, 250.0, 265.0, 280.0, 300.0, 315.0, 335.0, 355.0, 375.0, 400.0, 425.0, 450.0, 475.0, 500.0, 530.0, 560.0, 600.0, 630.0, 670.0, 710.0, 750.0, 800.0, 850.0, 900.0, 950.0, 1000.0, 1060.0, 1120.0, 1180.0, 1250.0, 1320.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0, 2120.0, 2240.0, 2360.0, 2500.0, 2650.0, 2800.0, 3000.0, 3150.0, 3350.0, 3550.0, 3750.0, 4000.0, 4250.0, 4500.0, 4750.0, 5000.0, 5300.0, 5600.0, 6000.0, 6300.0, 6700.0, 7100.0, 7500.0, 8000.0, 8500.0, 9000.0, 9500.0, 10000.0, 10600.0, 11200.0, 11800.0, 12500.0, 13200.0, 14000.0, 15000.0, 16000.0, 17000.0, 18000.0, 19000.0, 20000.0]\n",
    "onear_frequencies = np.array(onear_frequencies)\n",
    "def onear_score(fr):\n",
    "    fr = fr.copy()\n",
    "    fr.interpolate(onear_frequencies)\n",
    "    sl = np.logical_and(fr.frequency >= 50, fr.frequency <= 10000)\n",
    "    x = fr.frequency[sl]\n",
    "    xm = np.mean(x)\n",
    "    y = fr.error[sl]\n",
    "    ym = np.mean(y)\n",
    "    \n",
    "    slope, _, _, _, _ = scipy.stats.linregress(np.log(x), y)\n",
    "    std = np.std(y)\n",
    "    mean = np.mean(np.abs(y))\n",
    "    score = 114.490443008238 - 12.62 * std - 15.5163857197367 * np.abs(slope)\n",
    "        \n",
    "    return score, slope, mean, std, fr.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "harman_oe = FrequencyResponse.read_from_csv(os.path.join(ROOT_DIR, 'compensation', 'harman_over-ear_2018.csv'))\n",
    "onear = []\n",
    "errs = []\n",
    "names = []\n",
    "for fp in glob(os.path.join(ROOT_DIR, 'measurements', 'oratory1990', 'data', 'onear', '*', '*.csv')):\n",
    "    fr = FrequencyResponse.read_from_csv(fp)\n",
    "    fr.compensate(harman_oe, bass_boost_gain=0.0)\n",
    "    score, slope, mean, std, err = onear_score(fr)\n",
    "    onear.append([fr.name, f'{score:.0f}', f'{slope:.2f}', f'{mean:.2f}', f'{std:.2f}'])\n",
    "    errs.append(np.concatenate([[std, slope, score], err[::-1]]))\n",
    "    names.append(fr.name)\n",
    "    # TODO: ignore samples\n",
    "errs = np.vstack(errs)\n",
    "pd.DataFrame(errs.transpose(), columns=names).to_csv('onear_errs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onear = sorted(onear, key=lambda x: float(x[1]), reverse=True)\n",
    "onear_table = tabulate(\n",
    "    onear, headers=['Model', 'Score', 'Slope', 'Mean', 'STD'], tablefmt='orgtbl'\n",
    ").replace('+', '|').replace('|-', '|:')\n",
    "print(onear_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "harman_ie = FrequencyResponse.read_from_csv(os.path.join(ROOT_DIR, 'compensation', 'harman_in-ear_2019v2.csv'))\n",
    "inear = []\n",
    "errs = []\n",
    "names = []\n",
    "for fp in glob(os.path.join(ROOT_DIR, 'measurements', 'oratory1990', 'data', 'inear', '*', '*.csv')):\n",
    "    fr = FrequencyResponse.read_from_csv(fp)\n",
    "    fr.compensate(harman_ie, bass_boost_gain=0.0)\n",
    "    score, slope, mean, std, err = inear_score(fr)\n",
    "    inear.append([fr.name, f'{score:.0f}', f'{slope:.2f}', f'{mean:.2f}', f'{std:.2f}'])\n",
    "    errs.append(np.concatenate([[std, slope, mean, score], err[::-1]]))\n",
    "    names.append(fr.name)\n",
    "    # TODO: ignore samples\n",
    "errs = np.vstack(errs)\n",
    "pd.DataFrame(errs.transpose(), columns=names).to_csv('inear_errs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoEq (Python 3.7)",
   "language": "python",
   "name": "autoeq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
